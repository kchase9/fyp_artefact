{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import soundfile as sf\n",
    "\n",
    "with open(\"./creolese-audio-dataset/transcripts.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "with open(\"manifest.json\", \"w\") as fout:\n",
    "    for item in dataset:\n",
    "        filename = os.path.basename(item[\"audio\"])\n",
    "        audio_path = f\"./creolese-audio-dataset/Audio Files/{filename}\"\n",
    "\n",
    "        # Check file exists\n",
    "        if not os.path.exists(audio_path):\n",
    "            print(f\"Skipping missing file: {audio_path}\")\n",
    "            continue\n",
    "\n",
    "        audio, sr = sf.read(audio_path)\n",
    "        duration = len(audio) / sr\n",
    "\n",
    "        manifest_entry = {\n",
    "            \"audio_filepath\": audio_path,\n",
    "            \"duration\": duration,\n",
    "            \"text\": item[\"text\"]\n",
    "        }\n",
    "\n",
    "        fout.write(json.dumps(manifest_entry))\n",
    "        fout.write(\"\\n\")  #  ensure newline after each object\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_17s32WQZWF"
   },
   "source": [
    "Source: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/stt_multilingual_fastconformer_hybrid_large_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/path/to/nemo/examples/asr/speech_to_text_transducer/train_speech_to_text_transducer.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python /path/to/nemo/examples/asr/speech_to_text_transducer/train_speech_to_text_transducer.py \\\n",
    "  --config-path=\"./\" \\\n",
    "  --config-name=\"fastconformer_config.yaml\" \\\n",
    "  model.pretrained_model_name=\"stt_multilingual_fastconformer_hybrid_large_pc\" \\\n",
    "  exp_manager.exp_dir=\"./nemo_experiments\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6432,
     "status": "ok",
     "timestamp": 1746585963419,
     "user": {
      "displayName": "Kristeen Chase",
      "userId": "06112654503790926343"
     },
     "user_tz": 240
    },
    "id": "JBZ3eaMSfgPk",
    "outputId": "f040d449-4c3e-42b1-bf4e-b2b28b5e1837"
   },
   "outputs": [],
   "source": [
    "import nemo.collections.asr as nemo_asr\n",
    "\n",
    "asr_model = nemo_asr.models.EncDecHybridRNNTCTCBPEModel.from_pretrained(\"stt_multilingual_fastconformer_hybrid_large_pc\")\n",
    "\n",
    "\n",
    "\n",
    "audio = \"./creolese-audio-dataset/Audio Files/3.wav\"\n",
    "\n",
    "output = asr_model.transcribe([audio])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1746586378719,
     "user": {
      "displayName": "Kristeen Chase",
      "userId": "06112654503790926343"
     },
     "user_tz": 240
    },
    "id": "kiOa5xy3aiLu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bp-Nmb1tag1R",
    "outputId": "3419e633-7683-4582-e52c-f952fc490041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-05-08 02:34:55 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:34:55 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:17<00:00, 17.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 1.wav\n",
      "[NeMo I 2025-05-08 02:35:16 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:35:16 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:02<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 2.wav\n",
      "[NeMo I 2025-05-08 02:35:19 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:35:19 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:03<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 3.wav\n",
      "[NeMo I 2025-05-08 02:35:23 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:35:23 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:19<00:00, 19.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 4.wav\n",
      "[NeMo I 2025-05-08 02:35:43 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:35:43 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [01:35<00:00, 95.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 5.wav\n",
      "[NeMo I 2025-05-08 02:37:20 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:37:20 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|██████████████████████████████| 1/1 [02:04<00:00, 124.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 6.wav\n",
      "[NeMo I 2025-05-08 02:39:25 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:39:25 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:00<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 7.wav\n",
      "[NeMo I 2025-05-08 02:39:26 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:39:26 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [01:08<00:00, 68.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 8.wav\n",
      "[NeMo I 2025-05-08 02:40:35 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:40:35 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:03<00:00,  3.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 9.wav\n",
      "[NeMo I 2025-05-08 02:40:40 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:40:40 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:02<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 10.wav\n",
      "[NeMo I 2025-05-08 02:40:43 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:40:43 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:05<00:00,  5.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 11.wav\n",
      "[NeMo I 2025-05-08 02:40:49 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:40:49 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:01<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 12.wav\n",
      "[NeMo I 2025-05-08 02:40:51 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:40:51 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:00<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 13.wav\n",
      "[NeMo I 2025-05-08 02:40:52 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:40:52 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:00<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 14.wav\n",
      "[NeMo I 2025-05-08 02:40:53 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:40:53 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:02<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 15.wav\n",
      "[NeMo I 2025-05-08 02:40:56 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:40:56 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:06<00:00,  6.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 16.wav\n",
      "[NeMo I 2025-05-08 02:41:04 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:41:04 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:08<00:00,  8.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 17.wav\n",
      "[NeMo I 2025-05-08 02:41:12 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:41:12 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|██████████████████████████████| 1/1 [09:11<00:00, 551.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 18.wav\n",
      "[NeMo I 2025-05-08 02:50:34 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 02:50:34 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|██████████████████████████████| 1/1 [09:39<00:00, 579.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 19.wav\n",
      "[NeMo I 2025-05-08 03:00:15 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:00:15 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:05<00:00,  5.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 20.wav\n",
      "[NeMo I 2025-05-08 03:00:22 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:00:22 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:08<00:00,  8.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 21.wav\n",
      "[NeMo I 2025-05-08 03:00:32 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:00:32 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:25<00:00, 25.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 22.wav\n",
      "[NeMo I 2025-05-08 03:00:59 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:00:59 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [01:27<00:00, 87.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 23.wav\n",
      "[NeMo I 2025-05-08 03:02:27 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:02:27 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:16<00:00, 16.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 24.wav\n",
      "[NeMo I 2025-05-08 03:02:44 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:02:44 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:20<00:00, 20.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 25.wav\n",
      "[NeMo I 2025-05-08 03:03:04 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:03:04 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:31<00:00, 31.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 26.wav\n",
      "[NeMo I 2025-05-08 03:03:37 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:03:37 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:05<00:00,  5.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 27.wav\n",
      "[NeMo I 2025-05-08 03:03:43 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:03:43 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [01:06<00:00, 66.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 28.wav\n",
      "[NeMo I 2025-05-08 03:04:51 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:04:51 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:39<00:00, 39.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 29.wav\n",
      "[NeMo I 2025-05-08 03:05:31 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:05:31 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [01:10<00:00, 70.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 30.wav\n",
      "[NeMo I 2025-05-08 03:06:42 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:06:42 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:32<00:00, 32.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 31.wav\n",
      "[NeMo I 2025-05-08 03:07:15 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:07:15 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:27<00:00, 27.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 32.wav\n",
      "[NeMo I 2025-05-08 03:07:43 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:07:43 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:02<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 33.wav\n",
      "[NeMo I 2025-05-08 03:07:46 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:07:46 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:03<00:00,  3.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 34.wav\n",
      "[NeMo I 2025-05-08 03:07:50 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:07:50 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:13<00:00, 13.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 35.wav\n",
      "[NeMo I 2025-05-08 03:08:05 nemo_logging:393] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-05-08 03:08:05 nemo_logging:405] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: CUDA is not available\n",
      "Transcribing: 100%|███████████████████████████████| 1/1 [00:04<00:00,  4.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 36.wav\n"
     ]
    }
   ],
   "source": [
    "ground_truth = []\n",
    "predictions= []\n",
    "\n",
    "transcription_path = \"creolese-audio-dataset/transcripts.json\"\n",
    "\n",
    "with open(transcription_path, \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "for item in dataset:\n",
    "    filename = os.path.basename(item[\"audio\"])\n",
    "    audio_path = os.path.join(\"./creolese-audio-dataset/Audio Files\", filename)\n",
    "    reference = item[\"text\"]\n",
    "\n",
    "    try:\n",
    "        # Transcribe\n",
    "        result = asr_model.transcribe([audio_path])\n",
    "        hypothesis = result[0].text\n",
    "\n",
    "        # Append results\n",
    "        ground_truth.append(reference.lower())\n",
    "        predictions.append(hypothesis.lower())\n",
    "\n",
    "# Clear memory-heavy objects\n",
    "        del result\n",
    "        gc.collect()\n",
    "\n",
    "    except Exception as e:\n",
    "                print(f\"Skipping {audio_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "    # (Optional) Print progress\n",
    "    print(f\"Processed: {filename}\")\n",
    "\n",
    "# Final cleanup\n",
    "gc.collect()\n",
    "output_data = [{\"ref\": ref, \"hyp\": hyp} for ref, hyp in zip(ground_truth, predictions)]\n",
    "\n",
    "with open(\"./nvidia_pretrained_predictions.json\", \"w\") as out_file:\n",
    "        json.dump(output_data, out_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jiwer\n",
    "\n",
    "# === STEP 1: LOAD JSON ===\n",
    "with open(\"nvidia_pretrained_predictions.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "ground_truth = [entry['ref'] for entry in data]\n",
    "predictions = [entry['hyp'] for entry in data]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.9098\n",
      "CER: 0.4313\n",
      "MER: 0.8973\n"
     ]
    }
   ],
   "source": [
    "def custom_transform(text):\n",
    "        # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation (basic approach)\n",
    "    for char in \",.:;!?\\\"'()[]{}\":\n",
    "        text = text.replace(char, \"\")\n",
    "    # Remove extra spaces\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "# Apply transformation to each text individually\n",
    "ground_truth_transformed = [custom_transform(text) for text in ground_truth]\n",
    "predictions_transformed = [custom_transform(text) for text in predictions]\n",
    "\n",
    "# === STEP 4: COMPUTE METRICS ===\n",
    "wer = jiwer.wer(ground_truth_transformed, predictions_transformed)\n",
    "cer = jiwer.cer(ground_truth_transformed, predictions_transformed)\n",
    "mer = jiwer.mer(ground_truth_transformed, predictions_transformed)\n",
    "\n",
    "# === STEP 5: PRINT ===\n",
    "print(f\"WER: {wer:.4f}\")\n",
    "print(f\"CER: {cer:.4f}\")\n",
    "print(f\"MER: {mer:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMFUss3RG6EmaFpf8Qktwho",
   "mount_file_id": "1_6Qh-m4eLp2C5-QI3XoL2hdOlI6otJ_9",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
